import asyncio, json, uuid
from dotenv import load_dotenv
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_core.messages import HumanMessage
from langchain.callbacks.base import AsyncCallbackHandler

# ------------------------------------------------------------- #
load_dotenv()
SESSION_ID = str(uuid.uuid4())
checkpointer = MemorySaver()
MCP_CONFIG_FILE = "mcp.json"

class ToolPrint(AsyncCallbackHandler):
    async def on_tool_start(self, s, arg, *, run_id, **kw):
        name = s.get("name") if isinstance(s, dict) else str(s)
        print(f"ğŸ”§ {name} â†’ {arg}")
    async def on_tool_end(self, out, *, run_id, **kw):
        print(f"âœ… ê²°ê³¼ â† {str(out)[:120]}{'...' if len(str(out))>120 else ''}")

def load_servers():
    with open(MCP_CONFIG_FILE) as f:
        return json.load(f)["mcpServers"]

SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ PPT ì´ˆì•ˆ(JSON) ì‘ì„± ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‘ì—… ìˆœì„œ
1. ì‚¬ìš©ìê°€ PDFíŒŒì¼ì„ ì˜¬ë ¤ PPTë¡œ ë§Œë“¤ê³ ìí•˜ë©´, â†’ list_pdfs & chunk_pdf ë¡œ PDF ë‚´ìš©ì„ í™•ë³´.
2. ì‚¬ìš©ìì—ê²Œ ìŠ¬ë¼ì´ë“œ ì œëª©(ëª©ì°¨) ë¦¬ìŠ¤íŠ¸ë¥¼ ìš”ì²­.
3. ëª©ì°¨ê°€ ì£¼ì–´ì§€ë©´, ì‚¬ìš©ìì˜ PDF ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ˆì•ˆì„ ìƒì„±í›„ ì €ì¥, ê²½ë¡œë¥¼ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬.
4. ì´í›„ ìˆ˜ì •Â·ë³´ê°• ìš”ì²­ ì‹œ JSONì„ ì—…ë°ì´íŠ¸í•´ save_outline_json ì¬í˜¸ì¶œ.
   ê·¼ê±°Â·ë°ì´í„°ê°€ ì¶”ê°€ì ìœ¼ë¡œ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨ë˜ë©´, sequential thinking tool ë° exa search toolë“¤ì„ ì‚¬ìš©í•´ ì‹¬ì¸µ ìë£Œì¡°ì‚¬ë¥¼ ì§„í–‰í•œë‹¤.
   ìë£Œì¡°ì‚¬ë¡œ ì–»ì€ ê²°ê³¼ëŠ” slide ìš”ì†Œì— ì¶”ê°€(í‘œ, bulletList ë“±)í•œ ë’¤ ë‹¤ì‹œ ì €ì¥í•œë‹¤, 
   ìë£Œì¡°ì‚¬ë¥¼ í†µí•´ ì¶”ê°€í•œ ìš”ì†Œì—ëŠ” exa searchë¥¼ í†µí•´ ì–»ì€ì°¸ê³  urlsì™€ ì‹ ë¢°ë„ ì ìˆ˜ë¥¼ ë°˜ë“œì‹œ ì¶”ê°€í•œë‹¤.

ì‘ë‹µì€ ê¸°ë³¸ì ìœ¼ë¡œ í•œêµ­ì–´ë¥¼ ì‚¬ìš©í•˜ë˜, ì‚¬ìš©ìê°€ ë°”ê¾¸ë©´ ë”°ë¼ê°„ë‹¤.
"""

async def build_agent():
    servers = load_servers()
    tools   = await MultiServerMCPClient(servers).get_tools()
    llm     = ChatOpenAI(model="gpt-4o", max_tokens=8000)

    # â¬‡ï¸ here: ìœ„ì¹˜ ì¸ìˆ˜(ëª¨ë¸, íˆ´) + checkpointer
    agent = create_react_agent(
        llm,                       # â† í‚¤ì›Œë“œ ì œê±°
        tools,                     # â† ë‘ ë²ˆì§¸ ìœ„ì¹˜ ì¸ìˆ˜
        checkpointer=checkpointer,  # â† í‚¤ì›Œë“œ OK
        prompt=SYSTEM_PROMPT
    )
    print("ë¡œë“œëœ íˆ´:", [t.name for t in tools])
    return agent

async def main():
    agent = await build_agent()
    handler = ToolPrint()
    print("ğŸ’¬ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš” (exit ì…ë ¥ ì‹œ ì¢…ë£Œ)")

    while True:
        q = input("ğŸ‘¤ ")
        if q.lower() == "exit":
            break
        res = await agent.ainvoke(
            {"messages": [HumanMessage(content=q)]},
            config={"callbacks": [handler], "configurable": {"thread_id": SESSION_ID}},
        )
        print("\nğŸ¤–", res["messages"][-1].content, "\n")

if __name__ == "__main__":
    asyncio.run(main())
